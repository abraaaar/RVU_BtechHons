{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply RNNs to a real-world task by training an RNN to perform sentiment analysis on a set of movie reviews.\n",
    "# Use a dataset of movie reviews labeled as positive or negative.\n",
    "# Tokenize the text and convert it to sequences of word embeddings.\n",
    "# Implement the RNN for binary classification (positive/negative sentiment).\n",
    "# Measure the model's accuracy on a test set.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# from torchtext.legacy import data, datasets\n",
    "\n",
    "# Load the IMDb dataset\n",
    "TEXT = data.Field(tokenize='spacy', tokenizer_language='en_core_web_sm')\n",
    "LABEL = data.LabelField(dtype=torch.float)\n",
    "\n",
    "train_data, test_data = datasets.IMDb.splits(TEXT, LABEL)\n",
    "\n",
    "# Build the vocabulary\n",
    "TEXT.build_vocab(train_data, max_size=25000)\n",
    "LABEL.build_vocab(train_data)\n",
    "\n",
    "# Create data iterators\n",
    "train_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, test_data),\n",
    "    batch_size=64,\n",
    "    device=torch.device('cpu')\n",
    ")\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "        output, hidden = self.rnn(embedded)\n",
    "        return self.fc(hidden.squeeze(0))\n",
    "\n",
    "# Initialize the model\n",
    "input_dim = len(TEXT.vocab)\n",
    "embedding_dim = 100\n",
    "hidden_dim = 256\n",
    "output_dim = 1\n",
    "\n",
    "model = RNN(input_dim, embedding_dim, hidden_dim, output_dim)\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(5):\n",
    "    for batch in train_iterator:\n",
    "        text, labels = batch.text, batch.label\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(text).squeeze(1)\n",
    "        loss = criterion(predictions, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "\n",
    "# Evaluation\n",
    "def binary_accuracy(preds, y):\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float()\n",
    "    return correct.sum() / len(correct)\n",
    "\n",
    "acc = 0\n",
    "for batch in test_iterator:\n",
    "    text, labels = batch.text, batch.label\n",
    "    predictions = model(text).squeeze(1)\n",
    "    acc += binary_accuracy(predictions, labels).item()\n",
    "\n",
    "print(f\"Test Accuracy: {acc / len(test_iterator)}\") \n",
    "# This lab applies RNNs to sentiment analysis, a common NLP task. Students learn how to preprocess text data, build and train an RNN for classification, and evaluate the model's performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
